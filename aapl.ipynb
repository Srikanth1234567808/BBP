{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1867d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historical data for 63MOONS.NS...\n",
      "Download complete.\n",
      "Data range: 2005-06-20 to 2025-04-30\n",
      "Total records downloaded: 4899\n",
      "\n",
      "--- Analysis Results ---\n",
      "Number of days Close > Open (1): 1920\n",
      "Number of days Close < Open (-1): 2848\n",
      "Number of days Close == Open (0): 131\n",
      "Total trading days analyzed: 4899\n",
      "Ratio (-1s to 1s): 1.4833\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np  # Import numpy\n",
    "\n",
    "# Step 1: Download maximum available OHLC data\n",
    "ticker = '63MOONS.NS'  # You can change this to any ticker you like\n",
    "interval = '1d'  # Daily data\n",
    "\n",
    "print(f\"Downloading historical data for {ticker}...\")\n",
    "try:\n",
    "    # Use progress=False for cleaner output if not running interactively\n",
    "    data = yf.download(ticker, period='max', interval=interval, progress=False)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"No data downloaded for {ticker}. Cannot perform analysis.\")\n",
    "    else:\n",
    "        print(f\"Data range: {data.index.min().date()} to {data.index.max().date()}\")\n",
    "        print(f\"Total records downloaded: {len(data)}\")\n",
    "\n",
    "        # Step 2: Create a new column 'Close_vs_Open' using numpy.select\n",
    "        # This is generally faster and more robust than apply(axis=1)\n",
    "        conditions = [\n",
    "            data['Close'] > data['Open'],  # Condition for 1\n",
    "            data['Open'] > data['Close']   # Condition for -1 (equivalent to Close < Open)\n",
    "        ]\n",
    "        choices = [1, -1]\n",
    "        # np.select applies choices based on conditions, default is 0 if neither condition is met\n",
    "        data['Close_vs_Open'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "        # Step 3: Calculate counts and ratio\n",
    "        count_pos = (data['Close_vs_Open'] == 1).sum()\n",
    "        count_neg = (data['Close_vs_Open'] == -1).sum()\n",
    "        count_zero = (data['Close_vs_Open'] == 0).sum() # Optional: count days where Open == Close\n",
    "\n",
    "        # Handle potential division by zero for the ratio\n",
    "        if count_pos > 0:\n",
    "            ratio_neg_to_pos = count_neg / count_pos\n",
    "        else:\n",
    "            # Assign NaN or infinity if there are no positive days\n",
    "            ratio_neg_to_pos = np.nan if count_neg == 0 else float('inf')\n",
    "\n",
    "        # Step 4: Print results\n",
    "        print(\"\\n--- Analysis Results ---\")\n",
    "        print(f\"Number of days Close > Open (1): {count_pos}\")\n",
    "        print(f\"Number of days Close < Open (-1): {count_neg}\")\n",
    "        print(f\"Number of days Close == Open (0): {count_zero}\")\n",
    "        print(f\"Total trading days analyzed: {count_pos + count_neg + count_zero}\")\n",
    "        # Ensure the ratio format handles potential NaN or inf\n",
    "        if np.isnan(ratio_neg_to_pos):\n",
    "             print(\"Ratio (-1s to 1s): Undefined (no days with Close > Open)\")\n",
    "        elif np.isinf(ratio_neg_to_pos):\n",
    "             print(\"Ratio (-1s to 1s): Infinity (only days with Close < Open or Close == Open)\")\n",
    "        else:\n",
    "            print(f\"Ratio (-1s to 1s): {ratio_neg_to_pos:.4f}\") # Using 4 decimal places for more precision\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "    print(\"Please ensure the 'yfinance' and 'numpy' libraries are installed (`pip install yfinance numpy`)\")\n",
    "    print(\"Also check your internet connection and the ticker symbol.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af24c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for 649 unique tickers...\n",
      "\n",
      "Attempt 1/3 downloading batch: ['3MINDIA.NS', '63MOONS.NS', 'AARTIDRUGS.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ABSLAMC.NS', 'ACC.NS', 'ACE.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'ADSL.NS', 'ADVENZYMES.NS', 'AFFLE.NS', 'AHLUCONT.NS', 'AIAENG.NS', 'AJANTPHARM.NS', 'AJMERA.NS', 'ALEMBICLTD.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALLCARGO.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANTRAJ.NS', 'ANUP.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLO.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'ARTEMISMED.NS', 'ARVIND.NS', 'ARVINDFASN.NS', 'ASAHIINDIA.NS', 'ASALCBR.NS', 'ASHAPURMIN.NS', 'ASHOKA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTEC.NS', 'ASTERDM.NS', 'ASTRAL.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AFFLE.NS']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing downloaded data for batch: ['3MINDIA.NS', '63MOONS.NS', 'AARTIDRUGS.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ABSLAMC.NS', 'ACC.NS', 'ACE.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'ADSL.NS', 'ADVENZYMES.NS', 'AFFLE.NS', 'AHLUCONT.NS', 'AIAENG.NS', 'AJANTPHARM.NS', 'AJMERA.NS', 'ALEMBICLTD.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALLCARGO.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANTRAJ.NS', 'ANUP.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLO.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'ARTEMISMED.NS', 'ARVIND.NS', 'ARVINDFASN.NS', 'ASAHIINDIA.NS', 'ASALCBR.NS', 'ASHAPURMIN.NS', 'ASHOKA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTEC.NS', 'ASTERDM.NS', 'ASTRAL.NS']\n",
      "    - No valid data after dropna for AFFLE.NS\n",
      "\n",
      "Attempt 1/3 downloading batch: ['ASTRAMICRO.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATUL.NS', 'AUBANK.NS', 'AURIONPRO.NS', 'AUROPHARMA.NS', 'AVANTIFEED.NS', 'AXISBANK.NS', 'AXISCADES.NS', 'BAJAJ-AUTO.NS', 'BAJAJELEC.NS', 'BAJAJFINSV.NS', 'BAJAJHIND.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALAMINES.NS', 'BALKRISIND.NS', 'BALMLAWRIE.NS', 'BALPHARMA.NS', 'BALRAMCHIN.NS', 'BANCOINDIA.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBL.NS', 'BBTC.NS', 'BDL.NS', 'BECTORFOOD.NS', 'BEL.NS', 'BEML.NS', 'BEPL.NS', 'BERGEPAINT.NS', 'BFUTILITIE.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHEL.NS', 'BIOCON.NS', 'BIRLACORPN.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUESTARCO.NS', 'BOMDYEING.NS', 'BORORENEW.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS']\n",
      "Processing downloaded data for batch: ['ASTRAMICRO.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATUL.NS', 'AUBANK.NS', 'AURIONPRO.NS', 'AUROPHARMA.NS', 'AVANTIFEED.NS', 'AXISBANK.NS', 'AXISCADES.NS', 'BAJAJ-AUTO.NS', 'BAJAJELEC.NS', 'BAJAJFINSV.NS', 'BAJAJHIND.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALAMINES.NS', 'BALKRISIND.NS', 'BALMLAWRIE.NS', 'BALPHARMA.NS', 'BALRAMCHIN.NS', 'BANCOINDIA.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBL.NS', 'BBTC.NS', 'BDL.NS', 'BECTORFOOD.NS', 'BEL.NS', 'BEML.NS', 'BEPL.NS', 'BERGEPAINT.NS', 'BFUTILITIE.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHEL.NS', 'BIOCON.NS', 'BIRLACORPN.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUESTARCO.NS', 'BOMDYEING.NS', 'BORORENEW.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMLINFINE.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPACITE.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CARERATING.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIGNITITEC.NS', 'CIPLA.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COLPAL.NS', 'CONCOR.NS', 'COROMANDEL.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CSBBANK.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAMATICS.NS', 'DBL.NS', 'DBREALTY.NS', 'DCAL.NS', 'DCBBANK.NS', 'DCMSHRIRAM.NS', 'DCW.NS', 'DEEPAKFERT.NS']\n",
      "Processing downloaded data for batch: ['BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMLINFINE.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPACITE.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CARERATING.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIGNITITEC.NS', 'CIPLA.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COLPAL.NS', 'CONCOR.NS', 'COROMANDEL.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CSBBANK.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAMATICS.NS', 'DBL.NS', 'DBREALTY.NS', 'DCAL.NS', 'DCBBANK.NS', 'DCMSHRIRAM.NS', 'DCW.NS', 'DEEPAKFERT.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['DEEPAKNTR.NS', 'DELTACORP.NS', 'DHAMPURSUG.NS', 'DHANI.NS', 'DISHTV.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DLINKINDIA.NS', 'DMART.NS', 'DONEAR.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EDELWEISS.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'EKC.NS', 'ELECON.NS', 'ELECTCAST.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'EPL.NS', 'EQUITASBNK.NS', 'ERIS.NS', 'ESCORTS.NS', 'EXCELINDUS.NS', 'EXIDEIND.NS', 'FACT.NS', 'FCL.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINEORG.NS', 'FINPIPE.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GABRIEL.NS', 'GAEL.NS', 'GAIL.NS', 'GALLANTT.NS', 'GANECOS.NS', 'GANESHHOUC.NS', 'GARFIBRES.NS', 'GENESYS.NS', 'GENUSPOWER.NS', 'GEOJITFSL.NS']\n",
      "Processing downloaded data for batch: ['DEEPAKNTR.NS', 'DELTACORP.NS', 'DHAMPURSUG.NS', 'DHANI.NS', 'DISHTV.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DLINKINDIA.NS', 'DMART.NS', 'DONEAR.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EDELWEISS.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'EKC.NS', 'ELECON.NS', 'ELECTCAST.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'EPL.NS', 'EQUITASBNK.NS', 'ERIS.NS', 'ESCORTS.NS', 'EXCELINDUS.NS', 'EXIDEIND.NS', 'FACT.NS', 'FCL.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINEORG.NS', 'FINPIPE.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GABRIEL.NS', 'GAEL.NS', 'GAIL.NS', 'GALLANTT.NS', 'GANECOS.NS', 'GANESHHOUC.NS', 'GARFIBRES.NS', 'GENESYS.NS', 'GENUSPOWER.NS', 'GEOJITFSL.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['GEPIL.NS', 'GESHIP.NS', 'GHCL.NS', 'GICHSGFIN.NS', 'GICRE.NS', 'GILLETTE.NS', 'GIPCL.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GLOBUSSPR.NS', 'GMDCLTD.NS', 'GMMPFAUDLR.NS', 'GNFC.NS', 'GODFRYPHLP.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GOKEX.NS', 'GOLDIAM.NS', 'GOODLUCK.NS', 'GPIL.NS', 'GPPL.NS', 'GPTINFRA.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GREAVESCOT.NS', 'GRSE.NS', 'GSFC.NS', 'GSPL.NS', 'GTLINFRA.NS', 'GUJALKALI.NS', 'GUJGASLTD.NS', 'GULFOILLUB.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HATHWAY.NS', 'HAVELLS.NS', 'HCC.NS', 'HCG.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEMIPROP.NS', 'HERITGFOOD.NS']\n",
      "Processing downloaded data for batch: ['GEPIL.NS', 'GESHIP.NS', 'GHCL.NS', 'GICHSGFIN.NS', 'GICRE.NS', 'GILLETTE.NS', 'GIPCL.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GLOBUSSPR.NS', 'GMDCLTD.NS', 'GMMPFAUDLR.NS', 'GNFC.NS', 'GODFRYPHLP.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GOKEX.NS', 'GOLDIAM.NS', 'GOODLUCK.NS', 'GPIL.NS', 'GPPL.NS', 'GPTINFRA.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GREAVESCOT.NS', 'GRSE.NS', 'GSFC.NS', 'GSPL.NS', 'GTLINFRA.NS', 'GUJALKALI.NS', 'GUJGASLTD.NS', 'GULFOILLUB.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HATHWAY.NS', 'HAVELLS.NS', 'HCC.NS', 'HCG.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEMIPROP.NS', 'HERITGFOOD.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['HEROMOTOCO.NS', 'HESTERBIO.NS', 'HFCL.NS', 'HGINFRA.NS', 'HIKAL.NS', 'HIL.NS', 'HIMATSEIDE.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDOILEXP.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HITECH.NS', 'HONAUT.NS', 'HPL.NS', 'HSCL.NS', 'HUBTOWN.NS', 'HUDCO.NS', 'IBREALEST.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'ICIL.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFBIND.NS', 'IFCI.NS', 'IGARASHI.NS', 'IGL.NS', 'IIFL.NS', 'IMAGICAA.NS', 'IMFA.NS', 'INDHOTEL.NS', 'INDIAGLYCO.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIANHUME.NS', 'INDIGO.NS', 'INDOTECH.NS', 'INDRAMEDCO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFIBEAM.NS', 'INFY.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS']\n",
      "Processing downloaded data for batch: ['HEROMOTOCO.NS', 'HESTERBIO.NS', 'HFCL.NS', 'HGINFRA.NS', 'HIKAL.NS', 'HIL.NS', 'HIMATSEIDE.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDOILEXP.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HITECH.NS', 'HONAUT.NS', 'HPL.NS', 'HSCL.NS', 'HUBTOWN.NS', 'HUDCO.NS', 'IBREALEST.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'ICIL.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFBIND.NS', 'IFCI.NS', 'IGARASHI.NS', 'IGL.NS', 'IIFL.NS', 'IMAGICAA.NS', 'IMFA.NS', 'INDHOTEL.NS', 'INDIAGLYCO.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIANHUME.NS', 'INDIGO.NS', 'INDOTECH.NS', 'INDRAMEDCO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFIBEAM.NS', 'INFY.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['IOC.NS', 'IOLCP.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'ITC.NS', 'ITDCEM.NS', 'J&KBANK.NS', 'JAIBALAJI.NS', 'JAICORPLTD.NS', 'JAMNAAUTO.NS', 'JASH.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JCHAC.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JINDRILL.NS', 'JINDWORLD.NS', 'JISLJALEQS.NS', 'JKCEMENT.NS', 'JKIL.NS', 'JKLAKSHMI.NS', 'JKPAPER.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPASSOCIAT.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWHL.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUSTDIAL.NS', 'JYOTHYLAB.NS', 'JYOTISTRUC.NS', 'KABRAEXTRU.NS', 'KAJARIACER.NS', 'KAMATHOTEL.NS', 'KAMDHENU.NS', 'KARURVYSYA.NS', 'KCP.NS', 'KDDL.NS', 'KEC.NS', 'KEI.NS', 'KELLTONTEC.NS', 'KERNEX.NS', 'KIRIINDUS.NS', 'KIRLOSBROS.NS']\n",
      "Processing downloaded data for batch: ['IOC.NS', 'IOLCP.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'ITC.NS', 'ITDCEM.NS', 'J&KBANK.NS', 'JAIBALAJI.NS', 'JAICORPLTD.NS', 'JAMNAAUTO.NS', 'JASH.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JCHAC.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JINDRILL.NS', 'JINDWORLD.NS', 'JISLJALEQS.NS', 'JKCEMENT.NS', 'JKIL.NS', 'JKLAKSHMI.NS', 'JKPAPER.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPASSOCIAT.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWHL.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUSTDIAL.NS', 'JYOTHYLAB.NS', 'JYOTISTRUC.NS', 'KABRAEXTRU.NS', 'KAJARIACER.NS', 'KAMATHOTEL.NS', 'KAMDHENU.NS', 'KARURVYSYA.NS', 'KCP.NS', 'KDDL.NS', 'KEC.NS', 'KEI.NS', 'KELLTONTEC.NS', 'KERNEX.NS', 'KIRIINDUS.NS', 'KIRLOSBROS.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['KIRLOSENG.NS', 'KITEX.NS', 'KNRCON.NS', 'KOTAKBANK.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KRBL.NS', 'KSB.NS', 'KSCL.NS', 'KTKBANK.NS', 'LALPATHLAB.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LINDEINDIA.NS', 'LT.NS', 'LTTS.NS', 'LUPIN.NS', 'LUXIND.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHLIFE.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANGCHEFER.NS', 'MANGLMCEM.NS', 'MANINDS.NS', 'MANINFRA.NS', 'MARICO.NS', 'MARINE.NS', 'MARKSANS.NS', 'MARUTI.NS', 'MASTEK.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MIDHANI.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOIL.NS', 'MOREPENLAB.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MPSLTD.NS', 'MRF.NS']\n",
      "Processing downloaded data for batch: ['KIRLOSENG.NS', 'KITEX.NS', 'KNRCON.NS', 'KOTAKBANK.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KRBL.NS', 'KSB.NS', 'KSCL.NS', 'KTKBANK.NS', 'LALPATHLAB.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LINDEINDIA.NS', 'LT.NS', 'LTTS.NS', 'LUPIN.NS', 'LUXIND.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHLIFE.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANGCHEFER.NS', 'MANGLMCEM.NS', 'MANINDS.NS', 'MANINFRA.NS', 'MARICO.NS', 'MARINE.NS', 'MARKSANS.NS', 'MARUTI.NS', 'MASTEK.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MIDHANI.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOIL.NS', 'MOREPENLAB.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MPSLTD.NS', 'MRF.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['MRPL.NS', 'MSTCLTD.NS', 'MTNL.NS', 'MUTHOOTFIN.NS', 'NACLIND.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVINFLUOR.NS', 'NAVKARCORP.NS', 'NBCC.NS', 'NCC.NS', 'NECLIFE.NS', 'NELCO.NS', 'NEOGEN.NS', 'NESCO.NS', 'NESTLEIND.NS', 'NETWORK18.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NFL.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIITLTD.NS', 'NITINSPIN.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NOCIL.NS', 'NSIL.NS', 'NTPC.NS', 'OAL.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLECTRA.NS', 'ONGC.NS', 'OPTIEMUS.NS', 'ORIENTCEM.NS', 'ORIENTELEC.NS', 'ORISSAMINE.NS', 'PAGEIND.NS', 'PAISALO.NS', 'PANACEABIO.NS', 'PARACABLES.NS', 'PARAGMILK.NS', 'PATELENG.NS', 'PCJEWELLER.NS', 'PEL.NS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['NMDC.NS']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing downloaded data for batch: ['MRPL.NS', 'MSTCLTD.NS', 'MTNL.NS', 'MUTHOOTFIN.NS', 'NACLIND.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVINFLUOR.NS', 'NAVKARCORP.NS', 'NBCC.NS', 'NCC.NS', 'NECLIFE.NS', 'NELCO.NS', 'NEOGEN.NS', 'NESCO.NS', 'NESTLEIND.NS', 'NETWORK18.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NFL.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIITLTD.NS', 'NITINSPIN.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NOCIL.NS', 'NSIL.NS', 'NTPC.NS', 'OAL.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLECTRA.NS', 'ONGC.NS', 'OPTIEMUS.NS', 'ORIENTCEM.NS', 'ORIENTELEC.NS', 'ORISSAMINE.NS', 'PAGEIND.NS', 'PAISALO.NS', 'PANACEABIO.NS', 'PARACABLES.NS', 'PARAGMILK.NS', 'PATELENG.NS', 'PCJEWELLER.NS', 'PEL.NS']\n",
      "    - No valid data after dropna for NMDC.NS\n",
      "\n",
      "Attempt 1/3 downloading batch: ['PENIND.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PGIL.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PITTIENG.NS', 'PNB.NS', 'PNBHOUSING.NS', 'PNCINFRA.NS', 'POKARNA.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POLYPLEX.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'POWERMECH.NS', 'PRAJIND.NS', 'PRAKASH.NS', 'PREMEXPLN.NS', 'PRESTIGE.NS', 'PRICOLLTD.NS', 'PRINCEPIPE.NS', 'PRIVISCL.NS', 'PSB.NS', 'PTC.NS', 'QUESS.NS', 'QUICKHEAL.NS', 'RADICO.NS', 'RAIN.NS', 'RAJESHEXPO.NS', 'RALLIS.NS', 'RAMCOCEM.NS', 'RATNAMANI.NS', 'RAYMOND.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'REFEX.NS', 'RELIANCE.NS', 'RELIGARE.NS', 'RELINFRA.NS', 'RENUKA.NS', 'REPCOHOME.NS']\n",
      "Processing downloaded data for batch: ['PENIND.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PGIL.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PITTIENG.NS', 'PNB.NS', 'PNBHOUSING.NS', 'PNCINFRA.NS', 'POKARNA.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POLYPLEX.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'POWERMECH.NS', 'PRAJIND.NS', 'PRAKASH.NS', 'PREMEXPLN.NS', 'PRESTIGE.NS', 'PRICOLLTD.NS', 'PRINCEPIPE.NS', 'PRIVISCL.NS', 'PSB.NS', 'PTC.NS', 'QUESS.NS', 'QUICKHEAL.NS', 'RADICO.NS', 'RAIN.NS', 'RAJESHEXPO.NS', 'RALLIS.NS', 'RAMCOCEM.NS', 'RATNAMANI.NS', 'RAYMOND.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'REFEX.NS', 'RELIANCE.NS', 'RELIGARE.NS', 'RELINFRA.NS', 'RENUKA.NS', 'REPCOHOME.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['RESPONIND.NS', 'RGL.NS', 'RIIL.NS', 'RITES.NS', 'RKFORGE.NS', 'ROHLTD.NS', 'ROUTE.NS', 'RPOWER.NS', 'RTNPOWER.NS', 'RVNL.NS', 'SAIL.NS', 'SALZERELEC.NS', 'SANGHVIMOV.NS', 'SANOFI.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SDBL.NS', 'SEQUENT.NS', 'SHAKTIPUMP.NS', 'SHALBY.NS', 'SHARDACROP.NS', 'SHARDAMOTR.NS', 'SHAREINDIA.NS', 'SHILPAMED.NS', 'SHK.NS', 'SHREECEM.NS', 'SHRIPISTON.NS', 'SIYSIL.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SKIPPER.NS', 'SMLISUZU.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONATSOFTW.NS', 'SOUTHBANK.NS', 'SPAL.NS', 'SPANDANA.NS', 'SPARC.NS', 'SPMLINFRA.NS', 'SRF.NS', 'STAR.NS', 'STARCEMENT.NS', 'STLTECH.NS']\n",
      "Processing downloaded data for batch: ['RESPONIND.NS', 'RGL.NS', 'RIIL.NS', 'RITES.NS', 'RKFORGE.NS', 'ROHLTD.NS', 'ROUTE.NS', 'RPOWER.NS', 'RTNPOWER.NS', 'RVNL.NS', 'SAIL.NS', 'SALZERELEC.NS', 'SANGHVIMOV.NS', 'SANOFI.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SDBL.NS', 'SEQUENT.NS', 'SHAKTIPUMP.NS', 'SHALBY.NS', 'SHARDACROP.NS', 'SHARDAMOTR.NS', 'SHAREINDIA.NS', 'SHILPAMED.NS', 'SHK.NS', 'SHREECEM.NS', 'SHRIPISTON.NS', 'SIYSIL.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SKIPPER.NS', 'SMLISUZU.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONATSOFTW.NS', 'SOUTHBANK.NS', 'SPAL.NS', 'SPANDANA.NS', 'SPARC.NS', 'SPMLINFRA.NS', 'SRF.NS', 'STAR.NS', 'STARCEMENT.NS', 'STLTECH.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['SUBEXLTD.NS', 'SUDARSCHEM.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNFLAG.NS', 'SUNPHARMA.NS', 'SUNTECK.NS', 'SUPREMEIND.NS', 'SURYAROSNI.NS', 'SUVEN.NS', 'SUVENPHAR.NS', 'SUZLON.NS', 'SWANENERGY.NS', 'SWARAJENG.NS', 'SWSOLAR.NS', 'SYMPHONY.NS', 'SYNGENE.NS', 'TAJGVK.NS', 'TANLA.NS', 'TARC.NS', 'TASTYBITE.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TBZ.NS', 'TCPLPACK.NS', 'TCS.NS', 'TDPOWERSYS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'TEXINFRA.NS', 'TEXRAIL.NS', 'TFCILTD.NS', 'THANGAMAYL.NS', 'THEMISMED.NS', 'THERMAX.NS', 'THOMASCOOK.NS', 'TI.NS', 'TIINDIA.NS', 'TIMETECHNO.NS', 'TIMKEN.NS', 'TIRUMALCHM.NS', 'TITAN.NS']\n",
      "Processing downloaded data for batch: ['SUBEXLTD.NS', 'SUDARSCHEM.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNFLAG.NS', 'SUNPHARMA.NS', 'SUNTECK.NS', 'SUPREMEIND.NS', 'SURYAROSNI.NS', 'SUVEN.NS', 'SUVENPHAR.NS', 'SUZLON.NS', 'SWANENERGY.NS', 'SWARAJENG.NS', 'SWSOLAR.NS', 'SYMPHONY.NS', 'SYNGENE.NS', 'TAJGVK.NS', 'TANLA.NS', 'TARC.NS', 'TASTYBITE.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TBZ.NS', 'TCPLPACK.NS', 'TCS.NS', 'TDPOWERSYS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'TEXINFRA.NS', 'TEXRAIL.NS', 'TFCILTD.NS', 'THANGAMAYL.NS', 'THEMISMED.NS', 'THERMAX.NS', 'THOMASCOOK.NS', 'TI.NS', 'TIINDIA.NS', 'TIMETECHNO.NS', 'TIMKEN.NS', 'TIRUMALCHM.NS', 'TITAN.NS']\n",
      "\n",
      "Attempt 1/3 downloading batch: ['TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNICHEMLAB.NS', 'UNIONBANK.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'V2RETAIL.NS', 'VADILALIND.NS', 'VAIBHAVGBL.NS', 'VAKRANGEE.NS', 'VALIANTORG.NS', 'VARROC.NS', 'VBL.NS', 'VEDL.NS', 'VESUVIUS.NS', 'VGUARD.NS', 'VIMTALABS.NS', 'VINATIORGA.NS', 'VINDHYATEL.NS', 'VIPCLOTHNG.NS', 'VIPIND.NS', 'VISHNU.NS', 'VMART.NS', 'VOLTAMP.NS', 'VOLTAS.NS', 'VSTIND.NS', 'VTL.NS', 'WABAG.NS', 'WALCHANNAG.NS', 'WEBELSOLAR.NS', 'WELCORP.NS', 'WELENT.NS', 'WHIRLPOOL.NS', 'WOCKPHARMA.NS', 'WSTCSTPAPR.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS']\n",
      "Processing downloaded data for batch: ['TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNICHEMLAB.NS', 'UNIONBANK.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'V2RETAIL.NS', 'VADILALIND.NS', 'VAIBHAVGBL.NS', 'VAKRANGEE.NS', 'VALIANTORG.NS', 'VARROC.NS', 'VBL.NS', 'VEDL.NS', 'VESUVIUS.NS', 'VGUARD.NS', 'VIMTALABS.NS', 'VINATIORGA.NS', 'VINDHYATEL.NS', 'VIPCLOTHNG.NS', 'VIPIND.NS', 'VISHNU.NS', 'VMART.NS', 'VOLTAMP.NS', 'VOLTAS.NS', 'VSTIND.NS', 'VTL.NS', 'WABAG.NS', 'WALCHANNAG.NS', 'WEBELSOLAR.NS', 'WELCORP.NS', 'WELENT.NS', 'WHIRLPOOL.NS', 'WOCKPHARMA.NS', 'WSTCSTPAPR.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS']\n",
      "\n",
      "--- Saving 647 analysis results to open_vs_close_analysis.csv ---\n",
      "    Save successful.\n",
      "--- No tickers failed processing. ---\n",
      "\n",
      "--- Script finished ---\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- Configuration ---\n",
    "# Remove duplicates and ensure list type\n",
    "tickers_raw = ['3MINDIA.NS', '63MOONS.NS', 'AARTIDRUGS.NS', 'AARTIIND.NS', 'AAVAS.NS', 'ABB.NS', 'ABBOTINDIA.NS', 'ABCAPITAL.NS', 'ABFRL.NS', 'ACC.NS', 'ACE.NS', 'ADANIENT.NS', 'ADANIGREEN.NS', 'ADANIPORTS.NS', 'ADANIPOWER.NS', 'ADSL.NS', 'ADVENZYMES.NS', 'AFFLE.NS', 'AHLUCONT.NS', 'AIAENG.NS', 'AJANTPHARM.NS', 'AJMERA.NS', 'ALEMBICLTD.NS', 'ALKEM.NS', 'ALKYLAMINE.NS', 'ALLCARGO.NS', 'ALOKINDS.NS', 'AMBER.NS', 'AMBUJACEM.NS', 'ANANTRAJ.NS', 'ANUP.NS', 'APARINDS.NS', 'APLAPOLLO.NS', 'APLLTD.NS', 'APOLLO.NS', 'APOLLOHOSP.NS', 'APOLLOTYRE.NS', 'ARTEMISMED.NS', 'ARVIND.NS', 'ARVINDFASN.NS', 'ASAHIINDIA.NS', 'ASALCBR.NS', 'ASHAPURMIN.NS', 'ASHOKA.NS', 'ASHOKLEY.NS', 'ASIANPAINT.NS', 'ASTEC.NS', 'ASTERDM.NS', 'ASTRAL.NS', 'ASTRAMICRO.NS', 'ASTRAZEN.NS', 'ATGL.NS', 'ATUL.NS', 'AUBANK.NS', 'AURIONPRO.NS', 'AUROPHARMA.NS', 'AVANTIFEED.NS', 'AXISBANK.NS', 'AXISCADES.NS', 'BAJAJ-AUTO.NS', 'BAJAJELEC.NS', 'BAJAJFINSV.NS', 'BAJAJHIND.NS', 'BAJAJHLDNG.NS', 'BAJFINANCE.NS', 'BALAMINES.NS', 'BALKRISIND.NS', 'BALMLAWRIE.NS', 'BALPHARMA.NS', 'BALRAMCHIN.NS', 'BANCOINDIA.NS', 'BANDHANBNK.NS', 'BANKBARODA.NS', 'BANKINDIA.NS', 'BASF.NS', 'BATAINDIA.NS', 'BAYERCROP.NS', 'BBL.NS', 'BBTC.NS', 'BDL.NS', 'BECTORFOOD.NS', 'BEL.NS', 'BEML.NS', 'BEPL.NS', 'BERGEPAINT.NS', 'BFUTILITIE.NS', 'BHARATFORG.NS', 'BHARTIARTL.NS', 'BHEL.NS', 'BIOCON.NS', 'BIRLACORPN.NS', 'BLS.NS', 'BLUEDART.NS', 'BLUESTARCO.NS', 'BOMDYEING.NS', 'BORORENEW.NS', 'BOSCHLTD.NS', 'BPCL.NS', 'BRIGADE.NS', 'BRITANNIA.NS', 'BSE.NS', 'BSOFT.NS', 'CAMLINFINE.NS', 'CAMS.NS', 'CANBK.NS', 'CANFINHOME.NS', 'CAPACITE.NS', 'CAPLIPOINT.NS', 'CARBORUNIV.NS', 'CARERATING.NS', 'CASTROLIND.NS', 'CCL.NS', 'CDSL.NS', 'CEATLTD.NS', 'CENTRALBK.NS', 'CERA.NS', 'CESC.NS', 'CGCL.NS', 'CGPOWER.NS', 'CHALET.NS', 'CHAMBLFERT.NS', 'CHENNPETRO.NS', 'CHOLAFIN.NS', 'CHOLAHLDNG.NS', 'CIGNITITEC.NS', 'CIPLA.NS', 'COALINDIA.NS', 'COCHINSHIP.NS', 'COFORGE.NS', 'COLPAL.NS', 'CONCOR.NS', 'COROMANDEL.NS', 'CREDITACC.NS', 'CRISIL.NS', 'CROMPTON.NS', 'CSBBANK.NS', 'CUB.NS', 'CUMMINSIND.NS', 'CYIENT.NS', 'DABUR.NS', 'DALBHARAT.NS', 'DATAMATICS.NS', 'DBL.NS', 'DBREALTY.NS', 'DCAL.NS', 'DCBBANK.NS', 'DCMSHRIRAM.NS', 'DCW.NS', 'DEEPAKFERT.NS', 'DEEPAKNTR.NS', 'DELTACORP.NS', 'DHAMPURSUG.NS', 'DHANI.NS', 'DISHTV.NS', 'DIVISLAB.NS', 'DIXON.NS', 'DLF.NS', 'DLINKINDIA.NS', 'DMART.NS', 'DONEAR.NS', 'DRREDDY.NS', 'ECLERX.NS', 'EDELWEISS.NS', 'EICHERMOT.NS', 'EIDPARRY.NS', 'EIHOTEL.NS', 'EKC.NS', 'ELECON.NS', 'ELECTCAST.NS', 'ELGIEQUIP.NS', 'EMAMILTD.NS', 'ENDURANCE.NS', 'ENGINERSIN.NS', 'EPL.NS', 'EQUITASBNK.NS', 'ERIS.NS', 'ESCORTS.NS', 'EXCELINDUS.NS', 'EXIDEIND.NS', 'FACT.NS', 'FCL.NS', 'FEDERALBNK.NS', 'FINCABLES.NS', 'FINEORG.NS', 'FINPIPE.NS', 'FLUOROCHEM.NS', 'FORCEMOT.NS', 'FORTIS.NS', 'FSL.NS', 'GABRIEL.NS', 'GAEL.NS', 'GAIL.NS', 'GALLANTT.NS', 'GANECOS.NS', 'GANESHHOUC.NS', 'GARFIBRES.NS', 'GENESYS.NS', 'GENUSPOWER.NS', 'GEOJITFSL.NS', 'GEPIL.NS', 'GESHIP.NS', 'GHCL.NS', 'GICHSGFIN.NS', 'GICRE.NS', 'GILLETTE.NS', 'GIPCL.NS', 'GLAND.NS', 'GLAXO.NS', 'GLENMARK.NS', 'GLOBUSSPR.NS', 'GMDCLTD.NS', 'GMMPFAUDLR.NS', 'GNFC.NS', 'GODFRYPHLP.NS', 'GODREJAGRO.NS', 'GODREJCP.NS', 'GODREJIND.NS', 'GODREJPROP.NS', 'GOKEX.NS', 'GOLDIAM.NS', 'GOODLUCK.NS', 'GPIL.NS', 'GPPL.NS', 'GPTINFRA.NS', 'GRANULES.NS', 'GRAPHITE.NS', 'GRASIM.NS', 'GRAVITA.NS', 'GREAVESCOT.NS', 'GRSE.NS', 'GSFC.NS', 'GSPL.NS', 'GTLINFRA.NS', 'GUJALKALI.NS', 'GUJGASLTD.NS', 'GULFOILLUB.NS', 'HAL.NS', 'HAPPSTMNDS.NS', 'HATHWAY.NS', 'HAVELLS.NS', 'HCC.NS', 'HCG.NS', 'HCLTECH.NS', 'HDFCAMC.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEG.NS', 'HEMIPROP.NS', 'HERITGFOOD.NS', 'HEROMOTOCO.NS', 'HESTERBIO.NS', 'HFCL.NS', 'HGINFRA.NS', 'HIKAL.NS', 'HIL.NS', 'HIMATSEIDE.NS', 'HINDALCO.NS', 'HINDCOPPER.NS', 'HINDOILEXP.NS', 'HINDPETRO.NS', 'HINDUNILVR.NS', 'HINDZINC.NS', 'HITECH.NS', 'HONAUT.NS', 'HPL.NS', 'HSCL.NS', 'HUBTOWN.NS', 'HUDCO.NS', 'IBREALEST.NS', 'ICICIBANK.NS', 'ICICIGI.NS', 'ICICIPRULI.NS', 'ICIL.NS', 'IDBI.NS', 'IDEA.NS', 'IDFCFIRSTB.NS', 'IEX.NS', 'IFBIND.NS', 'IFCI.NS', 'IGARASHI.NS', 'IGL.NS', 'IIFL.NS', 'IMAGICAA.NS', 'IMFA.NS', 'INDHOTEL.NS', 'INDIAGLYCO.NS', 'INDIAMART.NS', 'INDIANB.NS', 'INDIANHUME.NS', 'INDIGO.NS', 'INDOTECH.NS', 'INDRAMEDCO.NS', 'INDUSINDBK.NS', 'INDUSTOWER.NS', 'INFIBEAM.NS', 'INFY.NS', 'INOXWIND.NS', 'INTELLECT.NS', 'IOB.NS', 'IOC.NS', 'IOLCP.NS', 'IPCALAB.NS', 'IRB.NS', 'IRCON.NS', 'IRCTC.NS', 'ITC.NS', 'ITDCEM.NS', 'J&KBANK.NS', 'JAIBALAJI.NS', 'JAICORPLTD.NS', 'JAMNAAUTO.NS', 'JASH.NS', 'JBCHEPHARM.NS', 'JBMA.NS', 'JCHAC.NS', 'JINDALSAW.NS', 'JINDALSTEL.NS', 'JINDRILL.NS', 'JINDWORLD.NS', 'JISLJALEQS.NS', 'JKCEMENT.NS', 'JKIL.NS', 'JKLAKSHMI.NS', 'JKPAPER.NS', 'JKTYRE.NS', 'JMFINANCIL.NS', 'JPASSOCIAT.NS', 'JPPOWER.NS', 'JSL.NS', 'JSWENERGY.NS', 'JSWHL.NS', 'JSWSTEEL.NS', 'JUBLFOOD.NS', 'JUSTDIAL.NS', 'JYOTHYLAB.NS', 'JYOTISTRUC.NS', 'KABRAEXTRU.NS', 'KAJARIACER.NS', 'KAMATHOTEL.NS', 'KAMDHENU.NS', 'KARURVYSYA.NS', 'KCP.NS', 'KDDL.NS', 'KEC.NS', 'KEI.NS', 'KELLTONTEC.NS', 'KERNEX.NS', 'KIRIINDUS.NS', 'KIRLOSBROS.NS', 'KIRLOSENG.NS', 'KITEX.NS', 'KNRCON.NS', 'KOTAKBANK.NS', 'KPITTECH.NS', 'KPRMILL.NS', 'KRBL.NS', 'KSB.NS', 'KSCL.NS', 'KTKBANK.NS', 'LALPATHLAB.NS', 'LAURUSLABS.NS', 'LEMONTREE.NS', 'LICHSGFIN.NS', 'LINDEINDIA.NS', 'LT.NS', 'LTTS.NS', 'LUPIN.NS', 'LUXIND.NS', 'M&M.NS', 'M&MFIN.NS', 'MAHABANK.NS', 'MAHLIFE.NS', 'MAHSCOOTER.NS', 'MAHSEAMLES.NS', 'MANAPPURAM.NS', 'MANGCHEFER.NS', 'MANGLMCEM.NS', 'MANINDS.NS', 'MANINFRA.NS', 'MARICO.NS', 'MARINE.NS', 'MARKSANS.NS', 'MARUTI.NS', 'MASTEK.NS', 'MAXHEALTH.NS', 'MAZDOCK.NS', 'MCX.NS', 'METROPOLIS.NS', 'MFSL.NS', 'MGL.NS', 'MIDHANI.NS', 'MINDACORP.NS', 'MMTC.NS', 'MOIL.NS', 'MOREPENLAB.NS', 'MOTILALOFS.NS', 'MPHASIS.NS', 'MPSLTD.NS', 'MRF.NS', 'MRPL.NS', 'MSTCLTD.NS', 'MTNL.NS', 'MUTHOOTFIN.NS', 'NACLIND.NS', 'NAM-INDIA.NS', 'NATCOPHARM.NS', 'NATIONALUM.NS', 'NAUKRI.NS', 'NAVINFLUOR.NS', 'NAVKARCORP.NS', 'NBCC.NS', 'NCC.NS', 'NECLIFE.NS', 'NELCO.NS', 'NEOGEN.NS', 'NESCO.NS', 'NESTLEIND.NS', 'NETWORK18.NS', 'NEULANDLAB.NS', 'NEWGEN.NS', 'NFL.NS', 'NH.NS', 'NHPC.NS', 'NIACL.NS', 'NIITLTD.NS', 'NITINSPIN.NS', 'NLCINDIA.NS', 'NMDC.NS', 'NOCIL.NS', 'NSIL.NS', 'NTPC.NS', 'OAL.NS', 'OBEROIRLTY.NS', 'OFSS.NS', 'OIL.NS', 'OLECTRA.NS', 'ONGC.NS', 'OPTIEMUS.NS', 'ORIENTCEM.NS', 'ORIENTELEC.NS', 'ORISSAMINE.NS', 'PAGEIND.NS', 'PAISALO.NS', 'PANACEABIO.NS', 'PARACABLES.NS', 'PARAGMILK.NS', 'PATELENG.NS', 'PCJEWELLER.NS', 'PEL.NS', 'PENIND.NS', 'PERSISTENT.NS', 'PETRONET.NS', 'PFC.NS', 'PFIZER.NS', 'PGEL.NS', 'PGHH.NS', 'PGIL.NS', 'PHOENIXLTD.NS', 'PIDILITIND.NS', 'PIIND.NS', 'PITTIENG.NS', 'PNB.NS', 'PNBHOUSING.NS', 'PNCINFRA.NS', 'POKARNA.NS', 'POLYCAB.NS', 'POLYMED.NS', 'POLYPLEX.NS', 'POWERGRID.NS', 'POWERINDIA.NS', 'POWERMECH.NS', 'PRAJIND.NS', 'PRAKASH.NS', 'PREMEXPLN.NS', 'PRESTIGE.NS', 'PRICOLLTD.NS', 'PRINCEPIPE.NS', 'PRIVISCL.NS', 'PSB.NS', 'PTC.NS', 'QUESS.NS', 'QUICKHEAL.NS', 'RADICO.NS', 'RAIN.NS', 'RAJESHEXPO.NS', 'RALLIS.NS', 'RAMCOCEM.NS', 'RATNAMANI.NS', 'RAYMOND.NS', 'RBLBANK.NS', 'RCF.NS', 'RECLTD.NS', 'REDINGTON.NS', 'REFEX.NS', 'RELIANCE.NS', 'RELIGARE.NS', 'RELINFRA.NS', 'RENUKA.NS', 'REPCOHOME.NS', 'RESPONIND.NS', 'RGL.NS', 'RIIL.NS', 'RITES.NS', 'RKFORGE.NS', 'ROHLTD.NS', 'ROUTE.NS', 'RPOWER.NS', 'RTNPOWER.NS', 'RVNL.NS', 'SAIL.NS', 'SALZERELEC.NS', 'SANGHVIMOV.NS', 'SANOFI.NS', 'SARDAEN.NS', 'SAREGAMA.NS', 'SBICARD.NS', 'SBILIFE.NS', 'SBIN.NS', 'SCHAEFFLER.NS', 'SCHNEIDER.NS', 'SCI.NS', 'SDBL.NS', 'SEQUENT.NS', 'SHAKTIPUMP.NS', 'SHALBY.NS', 'SHARDACROP.NS', 'SHARDAMOTR.NS', 'SHAREINDIA.NS', 'SHILPAMED.NS', 'SHK.NS', 'SHREECEM.NS', 'SHRIPISTON.NS', 'SIYSIL.NS', 'SJVN.NS', 'SKFINDIA.NS', 'SKIPPER.NS', 'SMLISUZU.NS', 'SOBHA.NS', 'SOLARINDS.NS', 'SONATSOFTW.NS', 'SOUTHBANK.NS', 'SPAL.NS', 'SPANDANA.NS', 'SPARC.NS', 'SPMLINFRA.NS', 'SRF.NS', 'STAR.NS', 'STARCEMENT.NS', 'STLTECH.NS', 'SUBEXLTD.NS', 'SUDARSCHEM.NS', 'SUMICHEM.NS', 'SUNDARMFIN.NS', 'SUNDRMFAST.NS', 'SUNFLAG.NS', 'SUNPHARMA.NS', 'SUNTECK.NS', 'SUPREMEIND.NS', 'SURYAROSNI.NS', 'SUVEN.NS', 'SUVENPHAR.NS', 'SUZLON.NS', 'SWANENERGY.NS', 'SWARAJENG.NS', 'SWSOLAR.NS', 'SYMPHONY.NS', 'SYNGENE.NS', 'TAJGVK.NS', 'TANLA.NS', 'TARC.NS', 'TASTYBITE.NS', 'TATACHEM.NS', 'TATACOMM.NS', 'TATACONSUM.NS', 'TATAELXSI.NS', 'TATAINVEST.NS', 'TATAMOTORS.NS', 'TATAPOWER.NS', 'TATASTEEL.NS', 'TBZ.NS', 'TCPLPACK.NS', 'TCS.NS', 'TDPOWERSYS.NS', 'TECHM.NS', 'TECHNOE.NS', 'TEJASNET.NS', 'TEXINFRA.NS', 'TEXRAIL.NS', 'TFCILTD.NS', 'THANGAMAYL.NS', 'THEMISMED.NS', 'THERMAX.NS', 'THOMASCOOK.NS', 'TI.NS', 'TIINDIA.NS', 'TIMETECHNO.NS', 'TIMKEN.NS', 'TIRUMALCHM.NS', 'TITAN.NS', 'TORNTPHARM.NS', 'TORNTPOWER.NS', 'TRENT.NS', 'TRIDENT.NS', 'TRITURBINE.NS', 'TRIVENI.NS', 'TTML.NS', 'TVSMOTOR.NS', 'UBL.NS', 'UCOBANK.NS', 'ULTRACEMCO.NS', 'UNICHEMLAB.NS', 'UNIONBANK.NS', 'UPL.NS', 'USHAMART.NS', 'UTIAMC.NS', 'V2RETAIL.NS', 'VADILALIND.NS', 'VAIBHAVGBL.NS', 'VAKRANGEE.NS', 'VALIANTORG.NS', 'VARROC.NS', 'VBL.NS', 'VEDL.NS', 'VESUVIUS.NS', 'VGUARD.NS', 'VIMTALABS.NS', 'VINATIORGA.NS', 'VINDHYATEL.NS', 'VIPCLOTHNG.NS', 'VIPIND.NS', 'VISHNU.NS', 'VMART.NS', 'VOLTAMP.NS', 'VOLTAS.NS', 'VSTIND.NS', 'VTL.NS', 'WABAG.NS', 'WALCHANNAG.NS', 'WEBELSOLAR.NS', 'WELCORP.NS', 'WELENT.NS', 'WHIRLPOOL.NS', 'WOCKPHARMA.NS', 'WSTCSTPAPR.NS', 'YESBANK.NS', 'ZEEL.NS', 'ZENSARTECH.NS', 'ZENTEC.NS', 'ABSLAMC.NS']\n",
    "tickers = sorted(list(set(tickers_raw))) # Remove duplicates and sort\n",
    "\n",
    "interval = '1d'\n",
    "period = 'max'\n",
    "batch_size = 50\n",
    "max_retries = 3\n",
    "retry_delay = 5  # seconds\n",
    "output_file = 'open_vs_close_analysis.csv'\n",
    "\n",
    "# Store results and failures\n",
    "results = []\n",
    "failed_tickers = [] # Tickers requested but data couldn't be processed\n",
    "\n",
    "# Suppress specific yfinance warnings if desired (optional)\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*Converting timezone from.*\")\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*No data found for ticker.*\") # yfinance handles this internally often\n",
    "\n",
    "# --- Analysis Function ---\n",
    "def analyze_ticker_data(ticker_symbol, open_prices, close_prices):\n",
    "    \"\"\"Analyzes open vs close prices for a single ticker.\"\"\"\n",
    "    # Ensure inputs are Series and drop NaNs based on both\n",
    "    combined = pd.DataFrame({'Open': open_prices, 'Close': close_prices}).dropna()\n",
    "\n",
    "    # Check if data remains after dropping NaNs\n",
    "    if combined.empty:\n",
    "        print(f\"    - No valid data after dropna for {ticker_symbol}\")\n",
    "        # Don't add to failed_tickers here, as it might have downloaded, just no usable data.\n",
    "        # The main loop will catch tickers that failed download entirely.\n",
    "        return\n",
    "\n",
    "    # Calculate comparison: 1 if Close > Open, -1 if Close < Open, 0 otherwise\n",
    "    conditions = [\n",
    "        combined['Close'] > combined['Open'],\n",
    "        combined['Open'] > combined['Close']\n",
    "    ]\n",
    "    choices = [1, -1]\n",
    "    close_vs_open = np.select(conditions, choices, default=0)\n",
    "\n",
    "    # Calculate counts\n",
    "    count_pos = (close_vs_open == 1).sum()\n",
    "    count_neg = (close_vs_open == -1).sum()\n",
    "    count_zero = (close_vs_open == 0).sum()\n",
    "    total_days = len(close_vs_open) # Use length of comparison array\n",
    "\n",
    "    # Calculate ratio, handling division by zero and inf cases\n",
    "    if count_pos > 0:\n",
    "        ratio_neg_to_pos = count_neg / count_pos\n",
    "    elif count_neg > 0: # count_pos is 0, but count_neg is not\n",
    "        ratio_neg_to_pos = float('inf')\n",
    "    else: # Both count_pos and count_neg are 0\n",
    "        ratio_neg_to_pos = np.nan\n",
    "\n",
    "    # Format ratio for output\n",
    "    if np.isnan(ratio_neg_to_pos):\n",
    "        ratio_str = None\n",
    "    elif np.isinf(ratio_neg_to_pos):\n",
    "        ratio_str = 'inf'\n",
    "    else:\n",
    "        ratio_str = round(ratio_neg_to_pos, 4)\n",
    "\n",
    "    # Append results\n",
    "    results.append({\n",
    "        'Ticker': ticker_symbol,\n",
    "        'Start Date': combined.index.min().date(),\n",
    "        'End Date': combined.index.max().date(),\n",
    "        'Days Close > Open': count_pos,\n",
    "        'Days Close < Open': count_neg,\n",
    "        'Days Close == Open': count_zero,\n",
    "        'Total Days': total_days,\n",
    "        'Ratio (-1s to 1s)': ratio_str\n",
    "    })\n",
    "    # print(f\"    + Successfully analyzed {ticker_symbol}\") # Optional: uncomment for verbose output\n",
    "\n",
    "# --- Batch Downloader with Retry ---\n",
    "def download_batch(batch):\n",
    "    \"\"\"Downloads a batch of tickers with retries.\"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            print(f\"\\nAttempt {attempt}/{max_retries} downloading batch: {batch}\")\n",
    "            # Use default yfinance behavior (no group_by) - returns MultiIndex columns ('Open'/'Ticker', 'Close'/'Ticker')\n",
    "            # threads=True is often beneficial for batch downloads\n",
    "            data = yf.download(\n",
    "                tickers=batch,\n",
    "                period=period,\n",
    "                interval=interval,\n",
    "                progress=False, # Show progress per ticker in batch\n",
    "                threads=True    # Use threading\n",
    "            )\n",
    "            # Check if *any* data was returned (even if some tickers failed)\n",
    "            if not data.empty:\n",
    "                return data\n",
    "            else:\n",
    "                # yfinance might return an empty DataFrame if all tickers in the batch fail\n",
    "                print(f\"Attempt {attempt} resulted in empty DataFrame for batch {batch}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt} failed for batch {batch} with exception: {e}\")\n",
    "\n",
    "        # Wait before retrying if not the last attempt\n",
    "        if attempt < max_retries:\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "        else:\n",
    "            print(f\"Max retries reached for batch {batch}. Marking as failed.\")\n",
    "\n",
    "    return None # Return None if all attempts failed\n",
    "\n",
    "# --- Main Execution ---\n",
    "print(f\"Starting analysis for {len(tickers)} unique tickers...\")\n",
    "processed_tickers = set() # Keep track of tickers successfully processed\n",
    "\n",
    "for i in range(0, len(tickers), batch_size):\n",
    "    batch = tickers[i:i + batch_size]\n",
    "    data = download_batch(batch)\n",
    "\n",
    "    if data is None or data.empty:\n",
    "        print(f\"-> Batch failed entirely or returned empty data: {batch}\")\n",
    "        # Add all tickers from this *requested* batch to failed_tickers\n",
    "        # Only add those not already processed/failed previously\n",
    "        failed_tickers.extend([t for t in batch if t not in processed_tickers and t not in failed_tickers])\n",
    "        continue # Move to the next batch\n",
    "\n",
    "    print(f\"Processing downloaded data for batch: {batch}\")\n",
    "\n",
    "    # Identify tickers actually present in the downloaded data's columns\n",
    "    # Default yf.download puts Ticker in level 1 of MultiIndex\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        tickers_in_data = data.columns.get_level_values(1).unique()\n",
    "    # Handle case where only one ticker was requested *and* downloaded successfully\n",
    "    elif isinstance(data.columns, pd.Index) and len(batch) == 1:\n",
    "         # If only one ticker was in the batch, yfinance returns a simple Index\n",
    "         # The columns will be 'Open', 'Close', etc.\n",
    "         # We reconstruct the expected structure for analysis function compatibility\n",
    "         ticker = batch[0]\n",
    "         if 'Open' in data.columns and 'Close' in data.columns:\n",
    "             analyze_ticker_data(ticker, data['Open'], data['Close'])\n",
    "             processed_tickers.add(ticker)\n",
    "         else:\n",
    "            print(f\"    - Missing 'Open' or 'Close' column for single ticker {ticker}\")\n",
    "            if ticker not in processed_tickers: failed_tickers.append(ticker)\n",
    "         continue # Skip the MultiIndex processing for this single ticker case\n",
    "    else:\n",
    "        # Unexpected data structure\n",
    "        print(f\"-> Unexpected data structure received for batch: {batch}\")\n",
    "        failed_tickers.extend([t for t in batch if t not in processed_tickers and t not in failed_tickers])\n",
    "        continue\n",
    "\n",
    "    # Process tickers found in the MultiIndex data\n",
    "    for ticker in tickers_in_data:\n",
    "        # Check if both Open and Close data are available for this ticker\n",
    "        open_col = ('Open', ticker)\n",
    "        close_col = ('Close', ticker)\n",
    "\n",
    "        if open_col in data.columns and close_col in data.columns:\n",
    "            try:\n",
    "                analyze_ticker_data(ticker, data[open_col], data[close_col])\n",
    "                processed_tickers.add(ticker) # Mark as processed successfully\n",
    "            except Exception as e:\n",
    "                print(f\"    ! Error analyzing {ticker}: {e}\")\n",
    "                if ticker not in processed_tickers: failed_tickers.append(ticker)\n",
    "        else:\n",
    "            # This ticker was in the data, but lacked Open or Close columns\n",
    "            print(f\"    - Missing 'Open' or 'Close' data for {ticker} within the downloaded batch.\")\n",
    "            if ticker not in processed_tickers: failed_tickers.append(ticker)\n",
    "\n",
    "    # Check which tickers from the original batch were *not* successfully processed\n",
    "    for ticker in batch:\n",
    "        if ticker not in processed_tickers and ticker not in failed_tickers:\n",
    "            # This ticker was requested but wasn't in tickers_in_data or failed analysis silently\n",
    "             print(f\"    - Ticker {ticker} requested but not found/processed in batch result.\")\n",
    "             failed_tickers.append(ticker)\n",
    "\n",
    "\n",
    "# --- Export Results to CSV ---\n",
    "if results:\n",
    "    print(f\"\\n--- Saving {len(results)} analysis results to {output_file} ---\")\n",
    "    df_results = pd.DataFrame(results)\n",
    "    # Sort results for consistency if desired\n",
    "    df_results.sort_values(by='Ticker', inplace=True)\n",
    "    try:\n",
    "        df_results.to_csv(output_file, index=False)\n",
    "        print(\"    Save successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error saving results CSV: {e}\")\n",
    "else:\n",
    "    print(\"\\n--- No results generated to save. ---\")\n",
    "\n",
    "\n",
    "# --- Save Failed Tickers ---\n",
    "# Ensure failed_tickers list contains unique entries before saving\n",
    "unique_failed_tickers = sorted(list(set(failed_tickers)))\n",
    "if unique_failed_tickers:\n",
    "    failed_file = 'failed_tickers.csv'\n",
    "    print(f\"--- Saving {len(unique_failed_tickers)} tickers with issues to {failed_file} ---\")\n",
    "    try:\n",
    "        pd.DataFrame(unique_failed_tickers, columns=['Ticker']).to_csv(failed_file, index=False)\n",
    "        print(\"    Save successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error saving failed tickers CSV: {e}\")\n",
    "else:\n",
    "    print(\"--- No tickers failed processing. ---\")\n",
    "\n",
    "print(\"\\n--- Script finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a1034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sum of 'Sum_Per_Date': 3.8353226513703174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "tickers = ['RELIANCE.NS', 'HDFCBANK.NS', 'BAJFINANCE.NS', 'SBIN.NS', 'ICICIBANK.NS']\n",
    "\n",
    "start_date = \"2013-01-15\"\n",
    "end_date = \"2018-01-15\"\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
    "    if not df.empty:\n",
    "        df[ticker] = ((df['Open'] - df['Close']) / df['Open'])\n",
    "        result = pd.concat([result, df[[ticker]]], axis=1)\n",
    "\n",
    "result['Sum_Per_Date'] = result.sum(axis=1)\n",
    "\n",
    "result['Modified_Sum'] = result['Sum_Per_Date'].apply(lambda x: -0.1 if x < -0.1 else x)\n",
    "\n",
    "result.to_csv('ticker_open_close_diff.csv')\n",
    "\n",
    "total_sum_original = result['Sum_Per_Date'].sum()\n",
    "total_sum_modified = result['Modified_Sum'].sum()\n",
    "\n",
    "print(\"\\nTotal sum of 'Sum_Per_Date':\", total_sum_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576364bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1000 random date ranges: 100%|██████████| 100/100 [01:35<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration  Start Date    End Date  Original Sum  Modified Sum\n",
      "0          1  2016-01-01  2016-12-31      2.476427      2.731579\n",
      "1          2  2015-03-03  2016-03-02      2.482814      2.582820\n",
      "2          3  2010-04-10  2011-04-10      1.851145      2.575075\n",
      "3          4  2023-02-07  2024-02-07      1.141107      1.214290\n",
      "4          5  2013-04-11  2014-04-11      0.007856      0.007856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "tickers = ['MRF.NS', 'PAGEIND.NS', 'HONAUT.NS', '3MINDIA.NS', 'ABBOTINDIA.NS']\n",
    "\n",
    "random_dates = []\n",
    "for _ in range(100):\n",
    "    year = random.randint(2010, 2024)\n",
    "    month = random.randint(1, 4)\n",
    "    day = random.randint(1, 11)\n",
    "    start = datetime(year, month, day)\n",
    "    end = start + timedelta(days=365)\n",
    "    random_dates.append((start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "for i, (start_date, end_date) in enumerate(tqdm(random_dates, desc=\"Processing 1000 random date ranges\")):\n",
    "    result = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\", progress=False)\n",
    "        if not df.empty:\n",
    "            df[ticker] = (df['Open'] - df['Close']) / df['Open']\n",
    "            result = pd.concat([result, df[[ticker]]], axis=1)\n",
    "\n",
    "    if not result.empty:\n",
    "        result['Sum_Per_Date'] = result.sum(axis=1)\n",
    "        result['Modified_Sum'] = result['Sum_Per_Date'].apply(lambda x: -0.1 if x < -0.1 else x)\n",
    "        total_sum_original = result['Sum_Per_Date'].sum()\n",
    "        total_sum_modified = result['Modified_Sum'].sum()\n",
    "    else:\n",
    "        total_sum_original = None\n",
    "        total_sum_modified = None\n",
    "\n",
    "    summary_results.append({\n",
    "        \"Iteration\": i + 1,\n",
    "        \"Start Date\": start_date,\n",
    "        \"End Date\": end_date,\n",
    "        \"Original Sum\": total_sum_original,\n",
    "        \"Modified Sum\": total_sum_modified\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "summary_df.to_csv(\"summary_of_100_runs.csv\", index=False)\n",
    "\n",
    "print(summary_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13ba2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily low time data will be saved in folder: 'daily_low_times_data'\n",
      "Processing 1 ticker(s) from 2025-01-01 to 2025-04-26 at 1h interval.\n",
      "\n",
      "📦 Processing batch 1 of 1\n",
      "Downloading hourly data for: 3MINDIA.NS\n",
      "   Processing daily lows for 3MINDIA.NS...\n",
      "❌ Error processing 3MINDIA.NS: Cannot index with multidimensional key\n",
      "\n",
      "🏁 Done! Daily low times CSV files saved in folder: 'daily_low_times_data'\n"
     ]
    }
   ],
   "source": [
    "# Ensure yfinance is installed. Uncomment the next line if running in an environment\n",
    "# where it might not be installed (like Google Colab or a fresh virtual environment)\n",
    "# !pip install yfinance tenacity pandas\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tenacity import retry, wait_fixed, stop_after_attempt\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "tickers = ['3MINDIA.NS'] # Add more tickers as needed e.g., ['RELIANCE.NS', 'TCS.NS']\n",
    "\n",
    "start_date = \"2025-01-01\"\n",
    "end_date = \"2025-04-26\" # yfinance end_date is exclusive for intraday data\n",
    "interval = \"1h\" # Fetching hourly data is necessary to find the lowest hour\n",
    "batch_size = 50 # Process tickers in batches if you have many\n",
    "\n",
    "# === CREATE FOLDER FOR OUTPUT ===\n",
    "folder_name = \"daily_low_times_data\" # Changed folder name for clarity\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(f\"Daily low time data will be saved in folder: '{folder_name}'\")\n",
    "\n",
    "# === RETRY LOGIC FOR DOWNLOADING EACH TICKER ===\n",
    "@retry(wait=wait_fixed(3), stop=stop_after_attempt(3)) # Retry 3 times with 3 sec wait\n",
    "def download_ticker(ticker):\n",
    "    \"\"\"Downloads historical data for a given ticker with retries.\"\"\"\n",
    "    print(f\"Downloading hourly data for: {ticker}\")\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        interval=interval,\n",
    "        progress=False, # Suppress yfinance download progress bar\n",
    "        # auto_adjust=True # Optional: Use adjusted prices\n",
    "        # prepost=True # Optional: Include pre/post market data if needed and available\n",
    "    )\n",
    "    # Check if 'Low' column exists, handle potential issues with downloaded data structure\n",
    "    if df.empty or 'Low' not in df.columns:\n",
    "        print(f\"⚠️ Warning: DataFrame is empty or missing 'Low' column for {ticker}.\")\n",
    "        return pd.DataFrame() # Return empty DataFrame to avoid errors later\n",
    "    return df\n",
    "\n",
    "# === PROCESS IN BATCHES ===\n",
    "print(f\"Processing {len(tickers)} ticker(s) from {start_date} to {end_date} at {interval} interval.\")\n",
    "\n",
    "for i in range(0, len(tickers), batch_size):\n",
    "    batch = tickers[i:i + batch_size]\n",
    "    # Calculate total batches correctly\n",
    "    total_batches = (len(tickers) + batch_size - 1) // batch_size\n",
    "    print(f\"\\n📦 Processing batch {i // batch_size + 1} of {total_batches}\")\n",
    "\n",
    "    for ticker in batch:\n",
    "        try:\n",
    "            # Download hourly data for the ticker\n",
    "            df_hourly = download_ticker(ticker)\n",
    "\n",
    "            # Proceed only if data was successfully downloaded and is not empty\n",
    "            if not df_hourly.empty:\n",
    "                print(f\"   Processing daily lows for {ticker}...\")\n",
    "\n",
    "                # --- CORE LOGIC FOR DAILY LOWS ---\n",
    "                # Ensure the index is a DatetimeIndex\n",
    "                df_hourly.index = pd.to_datetime(df_hourly.index)\n",
    "\n",
    "                # Create a 'Date' column from the index for grouping\n",
    "                # Use .tz_convert(None) if index is timezone-aware, then .date\n",
    "                if df_hourly.index.tz is not None:\n",
    "                     df_hourly['Date'] = df_hourly.index.tz_convert(None).date\n",
    "                else:\n",
    "                     df_hourly['Date'] = df_hourly.index.date\n",
    "\n",
    "\n",
    "                # Find the index (timestamp) of the minimum 'Low' for each 'Date'\n",
    "                # Using idxmin() on the grouped object gives the index label (Timestamp) of the min value within each group\n",
    "                idx_daily_low = df_hourly.groupby('Date')['Low'].idxmin()\n",
    "\n",
    "                # Select the rows corresponding to the daily lows using the obtained index\n",
    "                daily_low_data = df_hourly.loc[idx_daily_low]\n",
    "\n",
    "                # Refine the DataFrame to keep only the low price and add the timestamp as a column\n",
    "                # The index of daily_low_data is already the timestamp of the low\n",
    "                daily_low_summary = daily_low_data[['Low']].copy() # Select 'Low' column\n",
    "                daily_low_summary.rename(columns={'Low': 'Daily Low Price'}, inplace=True)\n",
    "                daily_low_summary['Timestamp of Low'] = daily_low_summary.index # Add timestamp column\n",
    "                daily_low_summary.index.name = 'Date' # Set the index name to 'Date'\n",
    "\n",
    "                # --- END CORE LOGIC ---\n",
    "\n",
    "                # Save the daily low times summary to a CSV file\n",
    "                file_path = os.path.join(folder_name, f\"{ticker}_daily_low_times.csv\")\n",
    "                # Save with Date as index, Timestamp and Low Price as columns\n",
    "                daily_low_summary.to_csv(file_path)\n",
    "                print(f\"✅ Saved daily low times for {ticker} to {file_path}\")\n",
    "\n",
    "            else:\n",
    "                # Handle cases where yfinance returned no data (or data missing 'Low')\n",
    "                print(f\"📉 No valid hourly data found for {ticker} in the specified period to calculate daily lows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch errors during download or processing for a specific ticker\n",
    "            # Provide more specific error context if possible\n",
    "            import traceback\n",
    "            print(f\"❌ Error processing {ticker}: {e}\")\n",
    "            # print(traceback.format_exc()) # Uncomment for detailed traceback if needed\n",
    "\n",
    "    # Optional sleep between batches to avoid rate-limiting\n",
    "    if len(tickers) > batch_size and i + batch_size < len(tickers):\n",
    "        print(f\"\\n--- Pausing for 5 seconds before next batch ---\")\n",
    "        time.sleep(5)\n",
    "\n",
    "print(f\"\\n🏁 Done! Daily low times CSV files saved in folder: '{folder_name}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
